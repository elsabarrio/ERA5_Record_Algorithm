---
title: "2-Final_models"
format: html
editor: visual
---

## Create data frame with data for all stations

To construct the final models, we first need to construct a data frame containing the data for all stations. To do so, we perform "column-wise concatenation". Specifically, we combine data from 36 separate stations, each corresponding to a different station, into a single larger data frame. Since these stations share some variables, the operation involves appending the columns of each station's data frame side by side, while the variables corresponding to the closest point to each of the stations are not the same, but we are gonna merge them into a unique variable.

```{r}
# Clear workspace
rm(list = ls())

# Set data directory
data_dir <- "../../../Data"
if(!dir.exists(data_dir)) stop("data_dir not found")

# Read list of observatories of interest. Based on previous work.
stations <- read.csv(file.path(data_dir,"geo_peninsula_zones.csv"))
idx <- which(!is.na(stations$Zona))
stations <- stations[idx,]
stations$point <- sapply(1:nrow(stations),
                         function(x){
                           aux <- as.character(round(stations$LON[x]))
                           if(grepl("^-",aux)){
                             aux <- paste0(substr(aux, 2, nchar(aux)),"W")
                           } else aux <- paste0(aux,"E")
                           })
stations$point <- paste0(round(stations$LAT),"N.",
                         stations$point)
# Corner points
cpoints <- c("45N.10W","45N.5E","35N.10W","35N.5E")

# Read Tx matrix
# Read the data for maximum temperatures
tx.mat <- read.csv(file.path(data_dir,"tx.data","Tx_mat.csv"))
tx.mat$Date <- as.Date(tx.mat$Date)
idx.y <- which(as.numeric(format(tx.mat$Date,"%Y")) > 1980 &
               as.numeric(format(tx.mat$Date,"%Y")) < 2011)
idx.d <- which(as.numeric(format(tx.mat$Date,"%m")) >=6 &
               as.numeric(format(tx.mat$Date,"%m")) <= 8)
stations$avg.Tx <- apply(X = tx.mat[intersect(idx.d,idx.y),-1],
                         MARGIN = 2,
                         FUN = function(x) mean(x, na.rm = T))/10
stations$sd.Tx <- apply(X = tx.mat[intersect(idx.d,idx.y),-1],
                         MARGIN = 2,
                         FUN = function(x) sd(x, na.rm = T))/10

# Add Tx mean and SD to the stations data frame
# for a period of interest (1981-2010)
summer_idx <- c(152:243)
tx3d[tx3d== -9999] <- NA
idx.ref <- 22:51
#idx.ref <- 52:64
tx_mean <- apply(tx3d[summer_idx,idx.ref,idx], 3, mean, na.rm = TRUE)/10
tx_sd <- apply(tx3d[summer_idx,idx.ref,idx], 3, sd, na.rm = TRUE)/10


# Read record indicators matrix
itx.mat <- read.csv(file.path(data_dir,"record.data","record.matrix.csv"))
itx.mat$Date <- as.Date(itx.mat$Date)

# Reshape data
TT <- length(table(format(itx.mat$Date,"%Y")))
LL <- nrow(itx.mat)/TT
SS <- nrow(stations)

# Data directory
outdir <- "../../../Results/final.models"
if(!dir.exists(outdir)) dir.create(outdir, recursive = T)

# Inint final data.frame
global.model.mat <- data.frame(STAID = rep(stations$STAID, each = nrow(itx.mat)),
                               Ix = c(as.matrix(itx.mat[,-1])),
                               t = rep(rep(1:TT, each = LL), SS),
                               l = rep(rep(1:LL, TT), SS),
                               LAT = rep(stations$LAT, each = nrow(itx.mat)),
                               LON = rep(stations$LON, each = nrow(itx.mat)),
                               CoastDist = rep(stations$LAT, each = nrow(itx.mat)))



# Set local data frames directory
df_dir <- file.path(data_dir,"local.dataframes/")

# Read rds with names of final variables
fin.var <- readRDS(file.path(outdir, "final.variables.rds"))

# Get all variables names
all.variables <- c("Ix", fin.var, "t","STAID", "LAT", "LON","Avg.Temp", "Altitude","Sd.Temp","CoastDist")

# Create empty data frame to store variables from all stations
global.model.mat <- matrix(ncol = length(all.variables), nrow = length(itx3d[-1,,]))

# Assgin colum names
colnames(global.model.mat ) <- all.variables


# Set variables before the loop starts
stations.dfs <- list.files(df_dir)
j <- 0
df_rownames <- c()
final_models <- c()
last_row_idx <- 0

# Convert global.model.mat to data.frame
global.model.mat <- as.data.frame(global.model.mat)

for (station.df in stations.dfs){
  
  j <- j+1
  print(j)
  
  # Read data frames
  bin_df <- read.csv(file.path(df_dir, station.df))
  
  row_idx <- (last_row_idx+1):(nrow(bin_df)+last_row_idx)
  
  last_row_idx <- last_row_idx + nrow(bin_df)
  
  
  # Reorder the columns to have the closer grid variables first and the further grid
  # variables after.
  plot_aux_df <- bin_df[,c(1:7, 12:15, 20:23, 8:11, 16:19, 24:29)]
  
  staid <- gsub("\\.df.csv$", "", station.df)
  df_rownames <- c(df_rownames,staid)
  print(staid)
  
  global.model.mat[row_idx,"STAID"] <- rep(staid, times = nrow(bin_df))
  
  sta_name <- stations$abb[stations$STAID==staid]
  lat.stat <- stations$LAT[stations$STAID==staid]
  lon.stat <- stations$LON[stations$STAID==staid]
  
  if (stations[grep(sta_name, stations$abb),]$LAT >= 0.5){
    lat <- paste0(round(stations[grep(sta_name, stations$abb),]$LAT,0),"N")
  }else{lat <- paste0(abs(round(stations[grep(sta_name, stations$abb),]$LAT,0)),"N")}
  
  if (stations[grep(sta_name, stations$abb),]$LON >= 0.5){
    lon <- paste0(round(stations[grep(sta_name, stations$abb),]$LON,0),"E")
  }else{lon <- paste0(abs(round(stations[grep(sta_name, stations$abb),]$LON,0)),"W")}
  
  closest.point.id <- paste0(lat,".",lon)
  selected_columns <- grep(closest.point.id, colnames(plot_aux_df), value = TRUE)
  other_columns <- names(plot_aux_df)[c(1:3, 16:29)]
  
  # Keep only one of the closer points
  plot_df <- plot_aux_df[,c(selected_columns,other_columns)]
  
  library(dplyr)
  plot_df <- plot_df %>% relocate(Ix.lag1,.after = Ix)
  plot_df <- plot_df  %>% relocate(trend,.after = t)
  
  
  # Now add lag variables for each of the geopotential variables
  aux_df <- plot_df[,grep("g[.]",names(plot_df))]
  for (i in 1:ncol(aux_df)){
    col_name <- paste0(names(aux_df)[i], ".lag1")
    aux_df[[col_name]] <- dplyr::lag(aux_df[,i], 1, 0)
  }
  
  # Find column indices where names end with ".lag1"
  lag1_indices <- grep("\\.lag1$", colnames(aux_df))
  
  # Combine data frames
  library(dplyr)
  
  
  # Assuming df1, df2, and df3 are your data frames
  full.df <- cbind(plot_df, aux_df[,lag1_indices])
  
  final.variables <- gsub("poly\\(([^,]+), 2\\)", "\\1", fin.var)
  
  # Get names of final variables
  final.variables.aux <- final.variables
  
  # Identify variables without explicit coordinates (the ones closest to the point being considered)
missing_coords_1 <- grep("^[^.]*\\.[^.]*\\.$", final.variables.aux) 
missing_coords_2 <- grep("\\.\\.lag1$", final.variables.aux)

# Modify cases that end with "." (coordinates missing)
final.variables.aux[missing_coords_1] <- gsub("\\.$", paste0(".", closest.point.id), final.variables.aux[missing_coords_1])

# Modify cases with "..lag1" (add coordinates in between points)
final.variables.aux[missing_coords_2] <- gsub("\\.\\.lag1$", paste0(".", closest.point.id, ".lag1"), final.variables.aux[missing_coords_2])

  # Add variables Ix and t to final variables
  gvars <- c("Ix", final.variables.aux, "t")
  gvars.aux <- c("Ix", final.variables, "t")
  
  # Add final variables to data frame
  for(var.idx in 1:length(gvars)){
    global.model.mat[row_idx,gvars.aux[var.idx]] <- full.df[[gvars[var.idx]]]
  }
  
  # Add latitude and longitude variables to data frame
  global.model.mat[row_idx,"LAT"] <- lat.stat
  global.model.mat[row_idx,"LON"] <- lon.stat
  
}

# Get STAIDs from data frame
staid.idx <- unique(global.model.mat[,colnames(global.model.mat) == "STAID"])
# Match staids to stations data frame
rows.idx <- match(staid.idx, stations$STAID)

# Reorder station data frame
stations.aux <- stations[rows.idx,]

# Reorder mean and standard deviation vectors
tx.mean.aux <- tx_mean[rows.idx]
tx.sd.aux <- tx_sd[rows.idx]

# Add final extra variables to data frames
global.model.mat[,"Avg.Temp"] <- rep(tx.mean.aux, each = nrow(global.model.mat)/voldim[3])
global.model.mat[,"Altitude"] <- rep(stations.aux$HGHT, each = nrow(global.model.mat)/voldim[3])
global.model.mat[,"Sd.Temp"] <- rep(tx.sd.aux, each = nrow(global.model.mat)/voldim[3])
global.model.mat[,"CoastDist"] <- rep(stations.aux$CoastDist/1000, each = nrow(global.model.mat)/voldim[3])
```

## M1: Simple global model

We begin by constructing a simple global model with the final variables selected from the local models as predictors.

```{r}
# Define file path
model_file <- file.path(wd, "Results/final.models/M1.RDS")
 
# Set training set
idx.train <- which(global.model.mat$t <= 51)
   
# Check if file exists
if (!file.exists(model_file)) {
   # File does not exist; run the code to compute and save the model
   
   # Get formula
   frm.1 <- as.formula(paste0("Ix~", capture.output(cat(fin.var, sep = "+"))))
   
   # Fit model
   full.M1 <- glm(formula = frm.1, data = global.model.mat[idx.train,], family = binomial(link = "logit"))
   
   M1.0 <- update(full.M1, .~1)
   
   M1 <- stepAIC(M1.0, direction = "both", scope = list(lower = M1.0, upper = full.M1), k = 10.82757)
   
   # Save model
   saveRDS(M1$formula, file = model_file)
 } else {
   # File exists; read the formula
   M1.formula <- readRDS(model_file)
   
   # Compute the model
   M1 <- glm(formula = M1.formula, data = global.model.mat[idx.train,], family = binomial(link = "logit"))
 }
```

## M2

```{r}
model_file <- file.path(wd, "Results/final.models/M2.RDS")

# Check if file exists
if (!file.exists(model_file)) {
  
  # File does not exist; run the code to compute and save the model
  # Get formula
  frm.2 <- as.formula(paste0("Ix~ (",capture.output(cat(fin.var, sep = "+")),") * LAT * LON "))
  
  # Define model before step
  full.M2 <- glm(formula = frm.2, data = global.model.mat[idx.train,], family = binomial(link = "logit"))
  
  # Set model for lower scope
  M2.0 <- update(full.M2, .~1)
  
  # Run step
  M2 <- stepAIC(M2.0, direction = "both", scope = list(lower = M2.0, upper = full.M2), k = 10.82757)
  
  saveRDS(M2$formula, file = file.path(wd,"Results/final.models/M2.RDS"))
  # Save model
  } else {
    
  # File exists; read the formula
  M2.formula <- readRDS(model_file)
  
  # Compute the model
  M2 <- glm(formula = M2.formula, data = global.model.mat[idx.train,], family = binomial(link = "logit"))
  
}
```

## M3

```{r}
# Define file path
model_file <- file.path(wd, "Results/final.models/M3.RDS")

# Check if file exists
if (!file.exists(model_file)) {
  
  # File does not exist; run the code to compute and save the model
    
  # Get formula
  frm.3 <- as.formula(paste0("Ix~ (",capture.output(cat(fin.var, sep = "+")),") * Avg.Temp * Sd.Temp "))
  
  # Define model before step
  full.M3 <- glm(formula = frm.3, data = global.model.mat[idx.train,], family = binomial(link = "logit"))
  
  # Set model for lower scope
  M3.0 <- update(full.M3, .~1)
  
  # Run step
  M3 <- stepAIC(M3.0, direction = "both", scope = list(lower = M3.0, upper = full.M3), k = 10.82757)
  
  # Save model
  saveRDS(M3$formula, file = file.path(wd,"Results/final.models/M3.RDS"))

} else {
  
  # File exists; read the formula
  M3.formula <- readRDS(model_file)
  
  # Compute the model
  M3 <- glm(formula = M3.formula, data = global.model.mat[idx.train,], family = binomial(link = "logit"))

}
```

## M4

```{r}
# Define file path
model_file <- file.path(wd, "Results/final.models/M4.RDS")

# Check if file exists
if (!file.exists(model_file)) {
  
  # File does not exist; run the code to compute and save the model
  # Get formula
  frm.4 <- as.formula(paste0("Ix~ (",capture.output(cat(fin.var, sep = "+")),") * Altitude * log(CoastDist) "))
  
  # Define model before step
  full.M4 <- glm(formula = frm.4, data = global.model.mat[idx.train,], family = binomial(link = "logit"))
  
  # Set model for lower scope
  M4.0 <- update(full.M4, .~1)
  
  # Run step
  M4 <- stepAIC(M4.0, direction = "both", scope = list(lower = M4.0, upper = full.M4), k = 10.82757)
  
  # Save model
  saveRDS(M4$formula, file = file.path(wd,"Results/final.models/M4.RDS"))

} else {
  
  # File exists; read the formula
  M4.formula <- readRDS(model_file)
  
  # Compute the model
  M4 <- glm(formula = M4.formula, data = global.model.mat[idx.train,], family = binomial(link = "logit"))
  
}
```

## Model's AUCs

```{r}
if(!is.element("MASS", row.names(installed.packages()))) install.packages("MASS")
library(MASS)
if(!is.element("pROC", row.names(installed.packages()))) install.packages("pROC")
library(pROC)

# Calculate full test AUC and coast test AUC
df.test <- global.model.mat[-idx.train,]

# Create matrices to save results
AUC.station.mat <- matrix(nrow = 4, ncol = nrow(stations))
colnames(AUC.station.mat) <- unique(global.model.mat$STAID)
final.models.mat <- matrix(nrow = 4, ncol = 5)
colnames(final.models.mat) <- c('k', "AUC", "AUC.coast", "AUC.inner", "AIC")

for (i in 1:4){
  
  # Get model
  model <- get(paste0('M',i))
  
  # Get number of parameters
  k <- length(coef(model))
  
  # Get global AUC
  predict.aux <- predict(model,newdata = df.test,type = "response")
  roc.aux <- roc(df.test$Ix, predict.aux, print.auc = TRUE)
  global.auc <- auc(roc.aux)
  
  # Get AUC from stations near the coast
  df.coast <- df.test[df.test$CoastDist < 50,]
  predict.coast <- predict(model,newdata = df.coast,type = "response")
  roc.coast <- roc(df.coast$Ix, predict.coast, print.auc = TRUE)
  coast.auc <- auc(roc.coast)
  
  # Get AUC from inner stations
  df.inner <- df.test[df.test$CoastDist> 50,]
  predict.inner <- predict(model,newdata = df.inner,type = "response")
  roc.inner <- roc(df.inner$Ix, predict.inner, print.auc = TRUE)
  inner.auc <- auc(roc.inner)
  
  # Get AIC value
  AIC.aux <- AIC(model)
  
  # Save measures in matrix
  final.models.mat[i,] <- c(k, global.auc, coast.auc, inner.auc, AIC.aux)
  
  # Get AUC values at each station
  for (staid in unique(global.model.mat$STAID)){
    
    # Get indices
    idx.AUC <- which(df.test$STAID == staid)
    
    # Calculate AUC
    roc.station <- roc(df.test[idx.AUC,]$Ix, predict.aux[idx.AUC], print.auc = TRUE)
    AUC.station<- auc(roc.station)
    
    # Save AUC
    AUC.station.mat[i, staid] <- AUC.station
}
  
}

# Save matrices
if (!file.exists(file.path(wd, 'Results/global.AUC.csv'))) {
  write.csv2(AUC.station.mat, file = file.path(wd, 'Results/global.AUC.csv'))
}

if (!file.exists(file.path(wd, 'Results/final.models.performance.csv'))) {
  write.csv2(final.models.mat, file = file.path(wd, 'Results/final.models.performance.csv'))
}
```

## Save M2 predict

```{r}

# Get global AUC
M2.predict <- predict(M2,newdata = df.test,type = "response")

M2.predict.df <- data.frame(STAID = df.test$STAID,
                            predict.test = M2.predict,
                            t = df.test$t,
                            l = rep(1:92, times = length(unique(df.test$t)*length(unique(df.test$STAID)))))

# Save M2 model's predict
if (!file.exists(file.path(wd, 'Results/M2.predict.csv'))) {
    write.csv2(M2.predict.df, file = file.path(wd, 'Results/M2.predict.csv'), row.names = FALSE)
}
```
